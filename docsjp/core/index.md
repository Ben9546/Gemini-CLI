# Gemini CLI コア

Gemini CLI のコアパッケージ (`packages/core`) は Gemini CLI のバックエンド部分であり、Gemini API との通信、ツールの管理、および `packages/cli` から送信されたリクエストの処理を担当します。Gemini CLI の一般的な概要については、[メインドキュメントページ](../index.md)を参照してください。

## このセクションのナビゲーション

- **[コアツール API](./tools-api.md):** ツールがコアによってどのように定義、登録、使用されるかに関する情報。

## コアの役割

Gemini CLI の `packages/cli` 部分がユーザーインターフェイスを提供するのに対し、`packages/core` は次の役割を担います。

- **Gemini API との対話:** Google Gemini API と安全に通信し、ユーザープロンプトを送信し、モデルの応答を受信します。
- **プロンプトエンジニアリング:** Gemini モデルの効果的なプロンプトを作成します。会話履歴、ツール定義、`GEMINI.md` ファイルからの指示コンテキストなどを組み込むことができます。
- **ツールの管理とオーケストレーション:**
  - 利用可能なツール（ファイルシステムツール、シェルコマンド実行など）を登録します。
  - Gemini モデルからのツール使用リクエストを解釈します。
  - 提供された引数で要求されたツールを実行します。
  - さらなる処理のために、ツール実行結果を Gemini モデルに返します。
- **セッションと状態管理:** 履歴や、一貫した対話に必要な関連コンテキストなど、会話の状態を追跡します。
- **設定:** API キーアクセス、モデル選択、ツール設定など、コア固有の設定を管理します。

## セキュリティに関する考慮事項

コアはセキュリティにおいて重要な役割を果たします。

- **API キー管理:** `GEMINI_API_KEY` を処理し、Gemini API との通信時に安全に使用されるようにします。
- **ツール実行:** ツールがローカルシステムと対話する場合（例: `run_shell_command`）、コア（およびその基になるツール実装）は、意図しない変更を防ぐためにサンドボックスメカニズムを頻繁に使用するなど、適切な注意を払って実行する必要があります。

## チャット履歴の圧縮

長い会話が Gemini モデルのトークン制限を超えないようにするため、コアにはチャット履歴圧縮機能が含まれています。

会話が設定されたモデルのトークン制限に近づくと、コアはモデルに送信する前に会話履歴を自動的に圧縮します。この圧縮は、伝達される情報の観点からは損失がありませんが、使用されるトークンの総数を削減します。

各モデルのトークン制限は、[Google AI ドキュメント](https://ai.google.dev/gemini-api/docs/models)で確認できます。

## モデルフォールバック

Gemini CLI にはモデルフォールバックメカニズムが含まれており、デフォルトの「pro」モデルがレート制限されていても CLI を引き続き使用できるようにします。

デフォルトの「pro」モデルを使用していて、CLI がレート制限されていることを検出した場合、現在のセッションでは自動的に「flash」モデルに切り替わります。これにより、中断することなく作業を続行できます。

## ファイル検出サービス

ファイル検出サービスは、現在のコンテキストに関連するプロジェクト内のファイルを見つける役割を担います。これは、`@` コマンドやファイルにアクセスする必要のあるその他のツールによって使用されます。

## メモリ検出サービス

メモリ検出サービスは、モデルにコンテキストを提供する `GEMINI.md` ファイルを見つけてロードする役割を担います。現在の作業ディレクトリから開始し、プロジェクトルートとユーザーのホームディレクトリまで階層的にこれらのファイルを検索します。また、サブディレクトリも検索します。

これにより、グローバル、プロジェクトレベル、およびコンポーネントレベルのコンテキストファイルを持つことができ、これらすべてが結合されてモデルに最も関連性の高い情報が提供されます。

[`/memory` コマンド](../cli/commands.md)を使用して、ロードされた `GEMINI.md` ファイルの内容を `show`、`add`、`refresh` できます。
