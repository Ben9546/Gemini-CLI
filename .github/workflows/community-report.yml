name: Generate Weekly Community Report üìä

on:
  schedule:
    - cron: '0 12 * * 1' # Run at 12:00 UTC on Monday
  workflow_dispatch:
    inputs:
      days:
        description: 'Number of days to look back for the report'
        required: true
        default: '7'

jobs:
  generate-report:
    name: Generate Report üìù
    runs-on: ubuntu-latest
    permissions:
      issues: write
      pull-requests: read
      discussions: read
      contents: read
      id-token: write

    steps:
      - name: Generate GitHub App Token üîë
        id: generate_token
        uses: actions/create-github-app-token@v1
        with:
          app-id: ${{ secrets.APP_ID }}
          private-key: ${{ secrets.PRIVATE_KEY }}

      - name: Generate Report üìú
        id: report
        env:
          GH_TOKEN: ${{ steps.generate_token.outputs.token }}
          REPO: ${{ github.repository }}
          DAYS: ${{ github.event.inputs.days || '7' }}
        run: |
          set -e

          START_DATE=$(date -u -d "$DAYS days ago" +'%Y-%m-%d')
          END_DATE=$(date -u +'%Y-%m-%d')
          echo "‚è≥ Generating report for contributions from $START_DATE to $END_DATE..."

          declare -A author_is_googler_cache # Renamed for clarity
          api_errors_googler_check=0

          check_googler_status() {
              local author=$1
              if [[ -z "$author" || "$author" == "null" ]]; then
                  return 1 # Invalid author, treat as non-Googler
              fi

              if [[ "$author" == *"[bot]" ]]; then
                  # Bots are generally not considered Googlers or community in this context,
                  # or are counted as community. Current logic counts them as community.
                  # Let's explicitly state they are treated as community for counting.
                  echo "ü§ñ $author is a bot, counted as community."
                  author_is_googler_cache[$author]=1 # 1 for non-Googler/community
                  return 1
              fi

              # Check cache first
              if [[ -v "author_is_googler_cache[$author]" ]]; then
                  return ${author_is_googler_cache[$author]}
              fi

              # Attempt to check org membership.
              # Note: This check relies on public membership in 'googlers' org or specific token permissions.
              # The current job token likely lacks org read permissions, so this may misclassify Googlers.
              http_status_code=$(gh api "orgs/googlers/members/$author" --silent -w "%{http_code}" -o /dev/null)
              api_exit_code=$?

              if [ "$api_exit_code" -eq 0 ] && [ "$http_status_code" -eq 204 ]; then # 204 No Content: membership confirmed and public
                  echo "üßë‚Äçüíª $author is likely a Googler (public membership)."
                  author_is_googler_cache[$author]=0 # 0 for Googler
              elif [ "$http_status_code" -eq 404 ]; then # 404 Not Found: not a member OR private membership
                  echo "üåç $author is a community contributor (or Googler with private org membership)."
                  author_is_googler_cache[$author]=1 # 1 for non-Googler/community
              else # Other errors (e.g., 403 Forbidden due to token permissions, rate limits, etc.)
                  echo "‚ö†Ô∏è Could not definitively determine Googler status for $author due to API error (HTTP: $http_status_code, gh exit: $api_exit_code). Assuming community contributor."
                  ((api_errors_googler_check++))
                  author_is_googler_cache[$author]=1 # Default to community
              fi
              return ${author_is_googler_cache[$author]}
          }

          googler_issues=0
          non_googler_issues=0
          googler_prs=0
          non_googler_prs=0

          echo "üîé Fetching issues and pull requests (limit 1000)..."
          # Note: gh search issues has an implicit limit (around 1000 items). For more, direct API pagination would be needed.
          # For a weekly report, 1000 should generally be sufficient.
          ITEMS_JSON=$(gh search issues --repo "$REPO" "created:>$START_DATE" --json author,isPullRequest,number --limit 1000)

          echo "${ITEMS_JSON}" | jq -r '.[] | @base64' | while IFS= read -r row_base64; do
              _jq() {
                  echo "${row_base64}" | base64 --decode | jq -r "${1}"
              }
              author_data=$(_jq '.author') # author can be null for deleted users
              if [[ "$author_data" == "null" || -z "$author_data" ]]; then
                login="ghost" # Assign a placeholder for deleted users
              else
                login=$(_jq '.author.login')
              fi
              is_pr=$(_jq '.isPullRequest')

              check_googler_status "$login"
              is_googler_result=$?

              if [[ "$is_googler_result" -eq 0 ]]; then # 0 means is_googler
                  if [[ "$is_pr" == "true" ]]; then
                      ((googler_prs++))
                  else
                      ((googler_issues++))
                  fi
              else # 1 means non_googler / community
                  if [[ "$is_pr" == "true" ]]; then
                      ((non_googler_prs++))
                  else
                      ((non_googler_issues++))
                  fi
              fi
          done

          googler_discussions=0
          non_googler_discussions=0
          all_discussion_nodes_json="[]" # Initialize as empty JSON array

          echo "üó£Ô∏è Fetching discussions (with pagination)..."
          discussion_query_template='
          query($q: String!, $first: Int!, $after: String) {
            search(query: $q, type: DISCUSSION, first: $first, after: $after) {
              nodes {
                ... on Discussion {
                  author {
                    login
                  }
                }
              }
              pageInfo {
                hasNextPage
                endCursor
              }
            }
          }'

          cursor=""
          has_next_page=true
          page_num=1

          while $has_next_page; do
            echo "Fetching discussions page $page_num..."
            query_vars=$(jq -n --arg q "repo:$REPO created:>$START_DATE" --argjson first 100 --argjson after "$cursor" '{q:$q, first:$first, after:$after}')

            API_RESPONSE=$(gh api graphql -f query="$discussion_query_template" -f variables="$query_vars")
            api_exit_code=$?

            if [ $api_exit_code -ne 0 ]; then
                echo "Error fetching discussions (page $page_num). GraphQL API call failed. Exit code: $api_exit_code"
                echo "Response: $API_RESPONSE"
                # Decide if to break or continue with partial data. For now, break.
                break
            fi

            page_nodes=$(echo "$API_RESPONSE" | jq '.data.search.nodes')
            all_discussion_nodes_json=$(echo "$all_discussion_nodes_json" "$page_nodes" | jq -s 'add') # Merge arrays

            current_page_info=$(echo "$API_RESPONSE" | jq '.data.search.pageInfo')
            has_next_page=$(echo "$current_page_info" | jq '.hasNextPage')
            new_cursor=$(echo "$current_page_info" | jq -r '.endCursor')

            if [[ "$new_cursor" == "null" || "$new_cursor" == "$cursor" ]]; then # Safety break for no new cursor
                has_next_page=false
            fi
            cursor=$new_cursor
            ((page_num++))

            # Safety break for too many pages, adjust as needed
            if [ "$page_num" -gt 50 ]; then
                echo "Warning: Exceeded 50 pages of discussions. Stopping."
                break
            fi
          done

          echo "Processing $(echo "$all_discussion_nodes_json" | jq 'length') discussions..."
          echo "$all_discussion_nodes_json" | jq -r '.[] | @base64' | while IFS= read -r row_base64; do
              _jq() {
                  echo "${row_base64}" | base64 --decode | jq -r "${1}"
              }
              author_data=$(_jq '.author')
              if [[ "$author_data" == "null" || -z "$author_data" ]]; then
                login="ghost"
              else
                login=$(_jq '.author.login')
              fi

              check_googler_status "$login"
              is_googler_result=$?

              if [[ "$is_googler_result" -eq 0 ]]; then
                  ((googler_discussions++))
              else
                  ((non_googler_discussions++))
              fi
          done

          echo "‚úçÔ∏è Generating report content..."
          REPORT_TITLE="Community Contribution Report: $START_DATE to $END_DATE"
          TOTAL_ISSUES=$((googler_issues + non_googler_issues))
          TOTAL_PRS=$((googler_prs + non_googler_prs))
          TOTAL_DISCUSSIONS=$((googler_discussions + non_googler_discussions))

          googler_classification_note=""
          if [ "$api_errors_googler_check" -gt 0 ]; then
              googler_classification_note="_Note: Googler classification encountered $api_errors_googler_check API errors and may be inaccurate. This check relies on public organization membership or specific token permissions not typically available to this workflow._"
          else
              googler_classification_note="_Note: Googler classification relies on public organization membership or specific token permissions. It may not capture all internal contributions if membership is private._"
          fi

          REPORT_BODY=$(cat <<EOF
          ### üíñ Community Contribution Report

          **Period:** $START_DATE to $END_DATE

          | Category | Googlers | Community | Total |
          |---|---:|---:|---:|
          | **Issues** | $googler_issues | $non_googler_issues | **$TOTAL_ISSUES** |
          | **Pull Requests** | $googler_prs | $non_googler_prs | **$TOTAL_PRS** |
          | **Discussions** | $googler_discussions | $non_googler_discussions | **$TOTAL_DISCUSSIONS** |

          ${googler_classification_note}

          _This report was generated automatically by a GitHub Action._
          EOF
          )

          echo "report_body<<EOF" >> $GITHUB_OUTPUT
          echo "$REPORT_BODY" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

          echo "üìä Community Contribution Report:"
          echo "$REPORT_BODY"

      - name: ü§ñ Get Insights from Report
        if: steps.report.outputs.report_body != ''
        uses: google-gemini/gemini-cli-action@41c0f1b3cbd1a0b284251bd1aac034edd07a3a2f
        env:
          GITHUB_TOKEN: ${{ steps.generate_token.outputs.token }}
        with:
          version: 0.1.9
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          OTLP_GCP_WIF_PROVIDER: ${{ secrets.OTLP_GCP_WIF_PROVIDER }}
          OTLP_GCP_SERVICE_ACCOUNT: ${{ secrets.OTLP_GCP_SERVICE_ACCOUNT }}
          OTLP_GOOGLE_CLOUD_PROJECT: ${{ secrets.OTLP_GOOGLE_CLOUD_PROJECT }}
          settings_json: |
            {
              "coreTools": [
                "run_shell_command(gh issue list)",
                "run_shell_command(gh pr list)",
                "run_shell_command(gh search issues)",
                "run_shell_command(gh search prs)"
              ]
            }
          prompt: |
            You are a helpful assistant that analyzes community contribution reports.
            Based on the following report, please provide a brief summary and highlight any interesting trends or potential areas for improvement.

            Report:
            ${{ steps.report.outputs.report_body }}
